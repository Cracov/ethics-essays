In this essay I reflect on the hypothetical situtation of working at car ride company and being tasked with implementing an unsupervised pricing model. In this I reflect on my position and anticipate some societal consequences.


Recent innovations in technology have resulted in companies providing transportation as a service. 
This could be anything from car rides to bike hires. The company I work for specialises in providing 
car rides, similar to services provided by Uber and Lyft. Currently, the price a user pays is calculated 
based on the following factors: distance, duration, demand for drivers, and traffic conditions. To 
boost driver’s earnings and the profitability of the company, I’ve been tasked with implementing an 
unsupervised machine learning model. This would predict the price point at which a user will accept 
a trip and continue to use the service in the future. To calculate the price, the new model would 
include factors such as the previous trips, frequency of use, the time of the trip and start & end 
location.


The usage of transportation as a service is useful to society, as seen by the rapid growth of Uber 
(Blystone, 2021). However, with the company looking to implement changes to its pricing, there are 
ethical challenges to be considered. The unsupervised learning algorithm looks to find trends in 
usage, improving its predictions as data is gathered in real-time. From setup, it acts as a ‘black-box’, 
where the engineer has little to no understanding of how prices are calculated (Rudin, 2019). Thus, 
this leads to potential unknown consequences and biases, as this model cannot reason (Lipton, 
2018). Considering new factors, the algorithm will now pick up usage trends in the data. For 
example, it would understand trends such as users being inclined to accept expensive trips late at 
night. As the user has limited alternative forms of transport, they are more likely to accept the 
‘optimised’ fee. However, the algorithm wouldn’t consider that this usage can be reflective of the 
groups an individual belongs to – such as being a woman or an LGBTQ+ person who may feel unsafe 
travelling home. Furthermore, specific minority groups such as low-income, disabled people with 
mobility issues are often dependent on services such as these as their main form of transport. The 
algorithm will pick up on this trend, which will lead to them paying higher prices than what they can 
afford. This leaves them with the difficult decision between limited mobility or further reducing their 
low income. Therefore, charging different prices based on customers’ data cannot be considered 
ethical conduct. This new algorithm has the potential to actively contribute to the negative biases 
currently experienced by oppressed groups within our society. Thus, much emphasis needs to be 
placed on this concern, while considering the implementation of this algorithm.
With the potential for this algorithm to be biased towards oppressed groups, there are further 
harms the business itself could experience. If this business is not seen to attend to ethical 
considerations, this could lead to a negative portrayal in the media, resulting in a reduced number of 
customers and profit. As an example, Uber was heavily criticised for charging significantly higher 
prices, through their dynamic pricing algorithm during the London Bridge terror attack. In response 
to criticism in the aftermath, they were forced to refund customers (BBC News, 2017). Not only did 
this lead to a negative portrayal of the business in the media, but it also illustrated the 
unsuitableness of pricing algorithms when dealing with emergencies. However, without the 
implementation of the algorithm, we risk ignoring the issue of low driver’s pay. The new algorithm 
would greatly boost pay, improving the situation for drivers – many of whom are low income, people 
of colour and immigrants (Smiley, 2020). Thus, it’s clear that there are multiple groups to consider 
when looking at such large changes in the pricing model. Nevertheless, there is an ethical balance to 
be struck concerning societal impact, which includes both unbiased treatment of oppressed groups 
and improved employee conditions.


In analysing responsibility, it’s important to note that for a business their fundamental goal is 
maximising profit, not societal impact (Dreher, 2015). Thus, it should be considered vital for 
stakeholders to play a part in encouraging ethical behaviour. The first point to focus on is the 
individual responsibility of an employee. As an employee within this company, I have an ethical 
responsibility for any project I work on. This contrasts with the idea that workers are apolitical in 
nature and is supported by movements such as ‘#TechWontBuildIt’. They argue employees should 
actively protest projects they consider unethical. An example of this movement’s effectiveness is 
Google being forced to drop a project on image recognition for use in the military. This was the 
result of internal pressure, with four thousand employees supporting the campaign (CostanzaChock, 2020). Related to this, it is argued that citizen professionalism is needed to encourage ethical 
behaviour. By encouraging employees to think of their role as a citizen, they would consider societal, 
political, and economic consequences in their role (Graeff, 2020). Citizens individually have limited 
influence, yet collectively they have substantial power. An example of this is the boycott of Uber for 
concerns over safety in London. Although having limited effect themselves, it adds to a succession of 
negative PR which companies struggle to shake off (Clayton, 2017). Thus, by citizens being vocal with 
ethical concerns they have with a company, they raise awareness to other citizens. This leaves 
businesses with little choice but to change their ways or risk becoming unprofitable.
To conclude, there are several potential harms in the use of algorithms for pricing – to both 
oppressed groups in society, and for a business itself. Despite the economic benefits, it would be 
unwise for a business to implement such an algorithm because of the potential long-term harm to 
their business, as well as to users. The wider implications of pricing algorithms strongly illustrate the 
complex nature of ethical responsibility. There are many stakeholders in society that impact what 
technologies are implemented. Although this essay focused solely on the individual responsibility of 
employees and citizens, other collective groups such as governments and businesses need to be 
considered in preventing unethical conduct.


Bibliography:
BBC News. (2017) Uber has refunded passengers after London Bridge terror attack. [online] BBC 
News. Available at: <https://www.bbc.co.uk/news/newsbeat-40158459> [Accessed 21 October 
2021]. 


Blystone, D. (2021) The Story of Uber. [online] Investopedia. Available at: 
<https://www.investopedia.com/articles/personal-finance/111015/story-uber.asp#:~:text=Uber%20Technologies%20Inc.%27s%20%28UBER%29%20explosive%20growth%20
and%20constant,private%20startup%20company%20in%20the%20world.%201%202> [Accessed 21 
October 2021]. 

Clayton, E. (2017) Does #BoycottUber really work?. [online] Ecnmy. Available at: 
<https://www.ecnmy.org/engage/does-boycottuber-really-work/> [Accessed 21 October 2021].


Costanza-Chock, S. (2020) Directions for Future Work: From #TechWontBuildIt to 
#DesignJustice. Design Justice,.


Dreher, J. (2015) Sustaining Hierarchy - Uber isn't sharing. Kings Review.


Graeff, E. (2020) The Responsibility to Not Design and the Need for Citizen Professionalism. Tech 
Otherwise. https://doi.org/10.21428/93b2c832.c8387014


Lipton, Z. (2018) The Mythos of Model Interpretability. Queue, 16(3), pp.31-57.


Rudin, C. (2019) Stop explaining black box machine learning models for high stakes decisions and use 
interpretable models instead. Nature Machine Intelligence, 1(5), pp.206-215.


Smiley, E. (2020) The racist business model behind Uber and Lyft | Erica Smiley. [online] The 
Guardian. Available at: <https://www.theguardian.com/commentisfree/2020/oct/29/uber-lyft-racist-business-model-prop-22> [Accessed 21 October 2021].
